{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a2e957a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_tool.all as gt\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "abac150d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.geometric(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8e155160",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'offline': {\n",
    "        \"school_friendship\": [\n",
    "            \"spanish_highschools__1\",\n",
    "            \"spanish_highschools__2\",\n",
    "            \"spanish_highschools__6\",\n",
    "            \"spanish_highschools__11_10\",\n",
    "            \"spanish_highschools__11_9\",\n",
    "        ],\n",
    "        \"school_contact\": [\n",
    "            \"sp_high_school_new__2011\",\n",
    "            \"sp_high_school_new__2012\",\n",
    "            \"sp_primary_school\",\n",
    "        ],\n",
    "        'email': [\n",
    "            \"email_enron\",\n",
    "            \"uni_email\",\n",
    "            \"email_eu\",\n",
    "            \"dnc\"\n",
    "        ]\n",
    "    },\n",
    "    'online': {\n",
    "        'facebook': [\n",
    "            \"facebook_wall\",\n",
    "            \"facebook_organizations__L1\",\n",
    "            \"facebook_organizations__L2\",\n",
    "            \"facebook_organizations__M1\",\n",
    "            \"ego_social__facebook_107\",\n",
    "            \"ego_social__facebook_1912\",\n",
    "            \"ego_social__facebook_combined\",\n",
    "        ],\n",
    "        'google_plus': [\n",
    "            \"ego_social__gplus_101133961721621664586\",\n",
    "            \"ego_social__gplus_100500197140377336562\",\n",
    "            \"ego_social__gplus_101133961721621664586\",\n",
    "            \"ego_social__gplus_114336431216099933033\",\n",
    "        ],\n",
    "        'twitter': [\n",
    "            \"twitter_15m\",\n",
    "            \"twitter\",\n",
    "        ],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "dd53c633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_graph(g, k):\n",
    "    \"\"\"\n",
    "    Creates a new graph by combining `k` disjoint copies of graph `g`.\n",
    "    \"\"\"\n",
    "    combined = gt.Graph()\n",
    "    vertex_maps = []\n",
    "\n",
    "    for _ in range(k):\n",
    "        g_copy = g.copy()\n",
    "        iterator = combined.add_vertex(g_copy.num_vertices())\n",
    "        node_map = {v: next(iterator) for v in g_copy.vertices()}\n",
    "        # Add edges with correct offset\n",
    "        for e in g_copy.edges():\n",
    "            src = int(e.source())\n",
    "            tgt = int(e.target())\n",
    "            combined.add_edge(node_map[src], node_map[tgt])\n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c889ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_tool.all as gt\n",
    "import random\n",
    "def extract_subgraph(g, node_set):\n",
    "    vfilt = g.new_vertex_property(\"bool\")\n",
    "    for v in node_set:\n",
    "        vfilt[int(v)] = True  # convert Vertex to int (vertex index)\n",
    "    gv = gt.GraphView(g, vfilt=vfilt)\n",
    "    return gt.Graph(gv, prune=True)\n",
    "    \n",
    "def forest_fire_sample(g, sample_size=500, pf=0.5):\n",
    "    \"\"\"\n",
    "    Forest Fire Sampling on a graph-tool Graph.\n",
    "    - g: graph-tool Graph\n",
    "    - sample_size: desired number of nodes in sample\n",
    "    - pf: forward burning probability\n",
    "    \"\"\"\n",
    "\n",
    "    visited = set()\n",
    "    not_visited = set(g.vertices())\n",
    "    to_visit = []\n",
    "\n",
    "    ego_count = 0\n",
    "    while len(visited) < sample_size:\n",
    "        if not to_visit or ego_count > sample_size:\n",
    "            to_visit = [np.random.choice(list(not_visited))]\n",
    "            ego_count = 0\n",
    "        \n",
    "        current = to_visit.pop()\n",
    "        if current in visited:\n",
    "            ego_count += 1\n",
    "            continue\n",
    "\n",
    "        visited.add(current)\n",
    "        not_visited.remove(current)\n",
    "\n",
    "        neighbors = list(current.out_neighbors())\n",
    "        scaled_num_neighbors = max(min(len(neighbors), 5), int(len(neighbors) * sample_size / g.num_vertices()))\n",
    "        num_to_burn = min(scaled_num_neighbors, np.random.geometric(pf))\n",
    "        num_samples = scaled_num_neighbors - num_to_burn\n",
    "        neighbors_sample = random.sample(neighbors, num_samples)\n",
    "        to_visit.extend(neighbors_sample)\n",
    "\n",
    "    return extract_subgraph(g, visited)\n",
    "\n",
    "def set_num_edges(g, num_edges):\n",
    "    # remove random edges until the graph has the desired number of edges\n",
    "    while g.num_edges() > num_edges:\n",
    "        edge = random.choice(list(g.edges()))\n",
    "        g.remove_edge(edge)\n",
    "    return g\n",
    "    \n",
    "def summary(g):\n",
    "    return \", \\t \".join([\n",
    "        f\"nodes: {g.num_vertices():.2f}\",\n",
    "        f\"edges: {g.num_edges():.2f}\",\n",
    "        f\"avg_degree: {2 * g.num_edges() / g.num_vertices():.2f}\",\n",
    "        f\"avg_clustering: {gt.global_clustering(g)[0]:.2f}\",\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "cee16c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_graph(g, full_name, g_type, path):\n",
    "    seen = set()\n",
    "    filepath = f\"{path}/{g_type}/{full_name}.edge\"\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "    with open(filepath, \"w\") as f:\n",
    "        for e in g.edges():\n",
    "            u, v = int(e.source()), int(e.target())\n",
    "            edge = tuple(sorted((u, v)))\n",
    "            if edge not in seen:\n",
    "                seen.add(edge)\n",
    "                f.write(f\"{edge[0]} {edge[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7f1f9e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Graph: spanish_highschools__1\n",
      "\t Original: \t nodes: 409.00, \t edges: 6509.00, \t avg_degree: 31.83, \t avg_clustering: 0.34\n",
      "\t Sampled: \t nodes: 400.00, \t edges: 6377.00, \t avg_degree: 31.89, \t avg_clustering: 0.34\n",
      "\n",
      " Graph: spanish_highschools__2\n",
      "\t Original: \t nodes: 238.00, \t edges: 2889.00, \t avg_degree: 24.28, \t avg_clustering: 0.47\n",
      "\n",
      " Graph: spanish_highschools__6\n",
      "\t Original: \t nodes: 534.00, \t edges: 9527.00, \t avg_degree: 35.68, \t avg_clustering: 0.45\n",
      "\t Sampled: \t nodes: 400.00, \t edges: 5778.00, \t avg_degree: 28.89, \t avg_clustering: 0.45\n",
      "\n",
      " Graph: spanish_highschools__11_10\n",
      "\t Original: \t nodes: 458.00, \t edges: 5866.00, \t avg_degree: 25.62, \t avg_clustering: 0.39\n",
      "\t Sampled: \t nodes: 400.00, \t edges: 5081.00, \t avg_degree: 25.41, \t avg_clustering: 0.40\n",
      "\n",
      " Graph: spanish_highschools__11_9\n",
      "\t Original: \t nodes: 515.00, \t edges: 5027.00, \t avg_degree: 19.52, \t avg_clustering: 0.34\n",
      "\t Sampled: \t nodes: 400.00, \t edges: 3831.00, \t avg_degree: 19.16, \t avg_clustering: 0.36\n",
      "\n",
      " Graph: sp_high_school_new__2011\n",
      "\t Original: \t nodes: 126.00, \t edges: 1709.00, \t avg_degree: 27.13, \t avg_clustering: 0.52\n",
      "\n",
      " Graph: sp_high_school_new__2012\n",
      "\t Original: \t nodes: 180.00, \t edges: 2220.00, \t avg_degree: 24.67, \t avg_clustering: 0.43\n",
      "\n",
      " Graph: sp_primary_school\n",
      "\t Original: \t nodes: 242.00, \t edges: 8317.00, \t avg_degree: 68.74, \t avg_clustering: 0.48\n",
      "\n",
      " Graph: email_enron\n",
      "\t Original: \t nodes: 36692.00, \t edges: 183831.00, \t avg_degree: 10.02, \t avg_clustering: 0.09\n",
      "\t Sampled: \t nodes: 400.00, \t edges: 2598.00, \t avg_degree: 12.99, \t avg_clustering: 0.30\n",
      "\n",
      " Graph: uni_email\n",
      "\t Original: \t nodes: 1133.00, \t edges: 5451.00, \t avg_degree: 9.62, \t avg_clustering: 0.17\n",
      "\t Sampled: \t nodes: 400.00, \t edges: 1913.00, \t avg_degree: 9.56, \t avg_clustering: 0.21\n",
      "\n",
      " Graph: email_eu\n",
      "\t Original: \t nodes: 265214.00, \t edges: 364481.00, \t avg_degree: 2.75, \t avg_clustering: 0.00\n",
      "\t Sampled: \t nodes: 400.00, \t edges: 1528.00, \t avg_degree: 7.64, \t avg_clustering: 0.24\n",
      "\n",
      " Graph: dnc\n",
      "\t Original: \t nodes: 2029.00, \t edges: 10429.00, \t avg_degree: 10.28, \t avg_clustering: 0.55\n",
      "\t Sampled: \t nodes: 400.00, \t edges: 7513.00, \t avg_degree: 37.56, \t avg_clustering: 0.67\n",
      "\n",
      " Graph: facebook_wall\n",
      "\t Original: \t nodes: 46952.00, \t edges: 183412.00, \t avg_degree: 7.81, \t avg_clustering: 0.09\n",
      "\t Sampled: \t nodes: 400.00, \t edges: 625.00, \t avg_degree: 3.12, \t avg_clustering: 0.26\n",
      "\n",
      " Graph: facebook_organizations__L1\n",
      "\t Original: \t nodes: 5793.00, \t edges: 30753.00, \t avg_degree: 10.62, \t avg_clustering: 0.26\n",
      "\t Sampled: \t nodes: 400.00, \t edges: 4036.00, \t avg_degree: 20.18, \t avg_clustering: 0.35\n",
      "\n",
      " Graph: facebook_organizations__L2\n",
      "\t Original: \t nodes: 5524.00, \t edges: 94218.00, \t avg_degree: 34.11, \t avg_clustering: 0.22\n",
      "\t Sampled: \t nodes: 400.00, \t edges: 2786.00, \t avg_degree: 13.93, \t avg_clustering: 0.26\n",
      "\n",
      " Graph: facebook_organizations__M1\n",
      "\t Original: \t nodes: 1429.00, \t edges: 19357.00, \t avg_degree: 27.09, \t avg_clustering: 0.26\n",
      "\t Sampled: \t nodes: 400.00, \t edges: 5452.00, \t avg_degree: 27.26, \t avg_clustering: 0.32\n",
      "\n",
      " Graph: ego_social__facebook_107\n",
      "\t Original: \t nodes: 1034.00, \t edges: 26749.00, \t avg_degree: 51.74, \t avg_clustering: 0.50\n",
      "\t Sampled: \t nodes: 400.00, \t edges: 9985.00, \t avg_degree: 49.92, \t avg_clustering: 0.59\n",
      "\n",
      " Graph: ego_social__facebook_1912\n",
      "\t Original: \t nodes: 747.00, \t edges: 30025.00, \t avg_degree: 80.39, \t avg_clustering: 0.70\n",
      "\t Sampled: \t nodes: 400.00, \t edges: 15520.00, \t avg_degree: 77.60, \t avg_clustering: 0.78\n",
      "\n",
      " Graph: ego_social__facebook_combined\n",
      "\t Original: \t nodes: 4039.00, \t edges: 88234.00, \t avg_degree: 43.69, \t avg_clustering: 0.52\n",
      "\t Sampled: \t nodes: 400.00, \t edges: 7639.00, \t avg_degree: 38.20, \t avg_clustering: 0.45\n",
      "\n",
      " Graph: ego_social__gplus_101133961721621664586\n",
      "\t Original: \t nodes: 780.00, \t edges: 21662.00, \t avg_degree: 55.54, \t avg_clustering: 0.37\n",
      "\t Sampled: \t nodes: 400.00, \t edges: 12102.00, \t avg_degree: 60.51, \t avg_clustering: 0.48\n",
      "\n",
      " Graph: ego_social__gplus_100500197140377336562\n",
      "\t Original: \t nodes: 638.00, \t edges: 14162.00, \t avg_degree: 44.39, \t avg_clustering: 0.29\n",
      "\t Sampled: \t nodes: 400.00, \t edges: 10451.00, \t avg_degree: 52.26, \t avg_clustering: 0.36\n",
      "\n",
      " Graph: ego_social__gplus_101133961721621664586\n",
      "\t Original: \t nodes: 780.00, \t edges: 21662.00, \t avg_degree: 55.54, \t avg_clustering: 0.37\n",
      "\t Sampled: \t nodes: 400.00, \t edges: 11986.00, \t avg_degree: 59.93, \t avg_clustering: 0.48\n",
      "\n",
      " Graph: ego_social__gplus_114336431216099933033\n",
      "\t Original: \t nodes: 461.00, \t edges: 4546.00, \t avg_degree: 19.72, \t avg_clustering: 0.32\n",
      "\t Sampled: \t nodes: 400.00, \t edges: 4084.00, \t avg_degree: 20.42, \t avg_clustering: 0.38\n",
      "\n",
      " Graph: twitter_15m\n",
      "\t Original: \t nodes: 87569.00, \t edges: 4708274.00, \t avg_degree: 107.53, \t avg_clustering: 0.02\n",
      "\t Sampled: \t nodes: 400.00, \t edges: 5492.00, \t avg_degree: 27.46, \t avg_clustering: 0.21\n",
      "\n",
      " Graph: twitter\n",
      "\t Original: \t nodes: 465017.00, \t edges: 833540.00, \t avg_degree: 3.58, \t avg_clustering: 0.00\n",
      "\t Sampled: \t nodes: 400.00, \t edges: 809.00, \t avg_degree: 4.04, \t avg_clustering: 0.01\n"
     ]
    }
   ],
   "source": [
    "source_dir = os.path.join(\"..\", \"..\", \"DATA\", \"netzschleuder\")\n",
    "target_dir = os.path.join(\"..\", \"..\", \"DATA\", \"processed\")\n",
    "\n",
    "network_list = [net for off_on in data_dict.values() for category in off_on.values() for net in category]\n",
    "# network_list = ['sp_high_school_new__2011']\n",
    "\n",
    "SAMPLE_SIZE = 400\n",
    "DO_SAMPLE_UP = True\n",
    "SET_NUM_EDGES = True\n",
    "\n",
    "samples = []\n",
    "for network in network_list:\n",
    "    # Load the graph\n",
    "    g = gt.load_graph(f\"{source_dir}/{network}.gt\")\n",
    "\n",
    "    # Get the number of vertices and edges\n",
    "    num_nodes = g.num_vertices()\n",
    "    num_edges = g.num_edges()\n",
    "\n",
    "    g.set_directed(False)\n",
    "    gt.remove_parallel_edges(g)\n",
    "    gt.remove_self_loops(g)    \n",
    "\n",
    "    # Print the number of vertices and edges\n",
    "    print(f\"\\n Graph: {network}\")\n",
    "    print(\"\\t Original: \\t\", summary(g))\n",
    "    # export_graph(g, network, \"original\", target_dir)\n",
    "\n",
    "    \n",
    "    if num_nodes < SAMPLE_SIZE:\n",
    "        if DO_SAMPLE_UP:\n",
    "            g_new = duplicate_graph(g, int(np.ceil(SAMPLE_SIZE / num_nodes)))\n",
    "            sample = forest_fire_sample(g_new, sample_size=SAMPLE_SIZE, pf=0.5)  \n",
    "        else:\n",
    "            sample = g\n",
    "    else:\n",
    "        sample = forest_fire_sample(g, sample_size=SAMPLE_SIZE, pf=0.5)    \n",
    "        print(\"\\t Sampled: \\t\", summary(sample))\n",
    "\n",
    "    samples.append(sample)\n",
    "\n",
    "min_edges = min([s.num_edges() for s in samples])\n",
    "for network, sample in zip(network_list, samples):\n",
    "    # reduce edges to the minimum\n",
    "    if SET_NUM_EDGES:\n",
    "        sample = set_num_edges(sample, min_edges)\n",
    "\n",
    "    dir_name = f\"sample_{\"edged_\" if SET_NUM_EDGES else \"\"}{\"max_\" if not DO_SAMPLE_UP else \"\"}{SAMPLE_SIZE}\"\n",
    "    export_graph(sample, network, dir_name, target_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "da8b9baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt.graph_draw(g, output_size=(600, 600), bg_color=(255, 255, 255, 255))\n",
    "# gt.graph_draw(sample, output_size=(600, 600), bg_color=(255, 255, 255, 255))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135a8bac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
